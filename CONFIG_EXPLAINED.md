# üéì Explica√ß√£o Detalhada: Sistema de Configura√ß√£o JSON

## üìñ O Que √â e Por Que Existe?

### Antes (C√≥digo Python)
```python
# Era assim - tudo hardcoded no c√≥digo Python
EXPERIMENTS = [
    ("tfidf_lr", create_tfidf_lr, {
        "tfidf__max_features": [3000, 5000],
        "tfidf__ngram_range": [(1,1), (1,3)]
    }),
    # ... muitos outros modelos ...
]
```

**Problema:** Para adicionar um modelo, voc√™ tinha que editar c√≥digo Python!

### Agora (JSON)
```json
{
  "models": {
    "tfidf_lr": { "configura√ß√£o aqui" }
  }
}
```

**Vantagem:** Voc√™ edita s√≥ um arquivo JSON, sem mexer em Python!

---

## üèóÔ∏è Estrutura do `config/pipelines.json`

O arquivo tem **4 se√ß√µes principais**:

```json
{
  "datasets": { ... },        // 1Ô∏è‚É£ Quais datasets voc√™ tem
  "cv_config": { ... },       // 2Ô∏è‚É£ Configura√ß√£o de cross-validation
  "models": { ... },          // 3Ô∏è‚É£ Defini√ß√£o dos modelos
  "experiments": [ ... ]      // 4Ô∏è‚É£ Quais experimentos rodar
}
```

Vou explicar cada uma em detalhes:

---

## 1Ô∏è‚É£ Se√ß√£o `datasets`

**O que √©:** Lista de datasets dispon√≠veis para treino.

```json
{
  "datasets": {
    "arcaico_moderno": "train_arcaico_moderno.csv",
    "complexo_simples": "train_complexo_simples.csv",
    "literal_dinamico": "train_literal_dinamico.csv"
  }
}
```

**Como funciona:**
- **Chave** (`arcaico_moderno`): Nome que voc√™ usa nos comandos
- **Valor** (`train_arcaico_moderno.csv`): Nome do arquivo CSV na pasta `data/`

**Exemplo de uso:**
```bash
uv run src/ep1/train.py --dataset arcaico_moderno --model tfidf_lr
                                  # ‚Üë usa esta chave
```

**Adicionar novo dataset:**
```json
{
  "datasets": {
    "arcaico_moderno": "train_arcaico_moderno.csv",
    "meu_novo_dataset": "meus_dados.csv"  // ‚Üê adicione aqui
  }
}
```

---

## 2Ô∏è‚É£ Se√ß√£o `cv_config`

**O que √©:** Configura√ß√µes para cross-validation (valida√ß√£o cruzada).

```json
{
  "cv_config": {
    "n_folds": 5,         // Quantas divis√µes (5-fold CV)
    "random_state": 42    // Seed para reprodutibilidade
  }
}
```

**Como funciona:**
- `n_folds`: N√∫mero de "folds" na valida√ß√£o cruzada (comum: 5 ou 10)
- `random_state`: Garante que os resultados sejam reproduz√≠veis

**Para mudar:**
```json
{
  "cv_config": {
    "n_folds": 10,        // ‚Üê mude para 10-fold CV
    "random_state": 123   // ‚Üê mude a seed
  }
}
```

---

## 3Ô∏è‚É£ Se√ß√£o `models` - A MAIS IMPORTANTE

**O que √©:** Define COMO cada modelo √© constru√≠do.

Existem **2 tipos** de modelos:

### Tipo A: `sklearn_pipeline` (Modelos sklearn padr√£o)

**Estrutura:**
```json
{
  "models": {
    "nome_do_modelo": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "nome_do_step",
          "class": "caminho.completo.da.Classe",
          "params": { "parametros": "valores" }
        }
      ]
    }
  }
}
```

**Exemplo Real - Regress√£o Log√≠stica:**
```json
{
  "models": {
    "tfidf_lr": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "tfidf",
          "class": "sklearn.feature_extraction.text.TfidfVectorizer",
          "params": {}
        },
        {
          "name": "clf",
          "class": "sklearn.linear_model.LogisticRegression",
          "params": {
            "max_iter": 2000,
            "n_jobs": 1
          }
        }
      ]
    }
  }
}
```

**Traduzindo para Python:**
```python
# O JSON acima equivale a este c√≥digo Python:
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

model = Pipeline([
    ("tfidf", TfidfVectorizer()),
    ("clf", LogisticRegression(max_iter=2000, n_jobs=1))
])
```

### Entendendo cada parte:

```json
{
  "name": "tfidf",  // ‚Üê Nome do step no pipeline (voc√™ escolhe)
  "class": "sklearn.feature_extraction.text.TfidfVectorizer",  // ‚Üê Classe Python
  "params": {}  // ‚Üê Par√¢metros passados para a classe
}
```

**Mais exemplos:**

#### Random Forest:
```json
{
  "meu_rf": {
    "type": "sklearn_pipeline",
    "steps": [
      {
        "name": "vectorizer",
        "class": "sklearn.feature_extraction.text.CountVectorizer",
        "params": {
          "max_features": 5000,
          "ngram_range": [1, 2]
        }
      },
      {
        "name": "clf",
        "class": "sklearn.ensemble.RandomForestClassifier",
        "params": {
          "n_estimators": 100,
          "random_state": 42,
          "n_jobs": -1
        }
      }
    ]
  }
}
```

#### SVM:
```json
{
  "tfidf_svm": {
    "type": "sklearn_pipeline",
    "steps": [
      {
        "name": "tfidf",
        "class": "sklearn.feature_extraction.text.TfidfVectorizer",
        "params": {
          "max_features": 10000
        }
      },
      {
        "name": "clf",
        "class": "sklearn.svm.SVC",
        "params": {
          "kernel": "linear",
          "C": 1.0
        }
      }
    ]
  }
}
```

### Tipo B: `custom` (Modelos customizados)

**O que √©:** Para modelos que precisam de c√≥digo Python especial.

```json
{
  "models": {
    "sbert_lr": {
      "type": "custom",
      "factory": "src.ep1.models.sbert.create_sbert_lr",
      "params": {}
    }
  }
}
```

**Como funciona:**
- `factory`: Caminho para uma fun√ß√£o Python que cria o modelo
- `params`: Par√¢metros passados para essa fun√ß√£o

**A fun√ß√£o Python:**
```python
# src/ep1/models/sbert.py
def create_sbert_lr():
    # C√≥digo especial para criar o modelo SBERT
    return pipeline
```

---

## 4Ô∏è‚É£ Se√ß√£o `experiments`

**O que √©:** Define quais modelos testar e com quais par√¢metros.

```json
{
  "experiments": [
    {
      "model": "tfidf_lr",
      "param_grid": {
        "tfidf__max_features": [3000, 5000],
        "tfidf__ngram_range": [[1, 1], [1, 3]]
      }
    }
  ]
}
```

**Como funciona:**

1. **`model`**: Nome do modelo (deve existir em `"models"`)
2. **`param_grid`**: Par√¢metros para testar (grid search)

### Entendendo `param_grid`:

**Formato:** `"step__parametro": [valores_para_testar]`

```json
{
  "param_grid": {
    "tfidf__max_features": [3000, 5000],  // ‚Üê Testa 3000 E 5000
    "clf__C": [0.1, 1.0, 10.0]            // ‚Üê Testa 0.1 E 1.0 E 10.0
  }
}
```

**O sistema testa TODAS as combina√ß√µes:**
- `max_features=3000` + `C=0.1`
- `max_features=3000` + `C=1.0`
- `max_features=3000` + `C=10.0`
- `max_features=5000` + `C=0.1`
- `max_features=5000` + `C=1.0`
- `max_features=5000` + `C=10.0`

Total: 2 √ó 3 = **6 experimentos**

---

## üéØ Exemplo Completo Passo a Passo

Vou criar um modelo novo do zero:

### Passo 1: Adicionar o modelo em `"models"`

```json
{
  "models": {
    "meu_modelo_novo": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "vectorizer",
          "class": "sklearn.feature_extraction.text.CountVectorizer",
          "params": {
            "max_features": 5000
          }
        },
        {
          "name": "clf",
          "class": "sklearn.naive_bayes.MultinomialNB",
          "params": {
            "alpha": 1.0
          }
        }
      ]
    }
  }
}
```

### Passo 2: Adicionar experimentos

```json
{
  "experiments": [
    {
      "model": "meu_modelo_novo",
      "param_grid": {
        "vectorizer__max_features": [3000, 5000, 10000],
        "clf__alpha": [0.5, 1.0, 2.0]
      }
    }
  ]
}
```

### Passo 3: Usar o modelo

```bash
# Treinar
uv run src/ep1/train.py --dataset arcaico_moderno --model meu_modelo_novo --save

# Usar para predi√ß√£o
uv run predict_cli.py --model meu_modelo_novo --text "Teste"
```

---

## üîç Como o Sistema L√™ o JSON

### 1. Carregar configura√ß√£o:
```python
from src.ep1.config import get_default_config

config = get_default_config()
# L√™ automaticamente config/pipelines.json
```

### 2. Ver o que foi carregado:
```python
# Ver datasets
print(config.datasets)
# {'arcaico_moderno': 'train_arcaico_moderno.csv', ...}

# Ver modelos dispon√≠veis
print(list(config.models.keys()))
# ['tfidf_lr', 'tfidf_sgd', ...]

# Ver configura√ß√£o de CV
print(config.cv_config)
# {'n_folds': 5, 'random_state': 42}
```

### 3. Criar um modelo:
```python
# O sistema l√™ o JSON e cria o modelo automaticamente
model = config.get_model("tfidf_lr")
print(model)
# Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LogisticRegression(...))])
```

### 4. Pegar experimentos:
```python
experiments = config.get_experiments()
for model_name, model_factory, param_grid in experiments:
    print(f"Modelo: {model_name}")
    print(f"Par√¢metros: {param_grid}")
```

---

## üí° Casos de Uso Pr√°ticos

### Caso 1: Mudar par√¢metros de um modelo

**Antes (sem JSON):**
```python
# Tinha que editar c√≥digo Python
def create_tfidf_lr():
    return Pipeline([
        ("tfidf", TfidfVectorizer()),  # ‚Üê editar aqui
        ("clf", LogisticRegression(max_iter=2000))  # ‚Üê e aqui
    ])
```

**Agora (com JSON):**
```json
{
  "models": {
    "tfidf_lr": {
      "steps": [
        {
          "name": "tfidf",
          "params": {
            "max_features": 10000  // ‚Üê s√≥ muda aqui!
          }
        }
      ]
    }
  }
}
```

### Caso 2: Adicionar novo algoritmo

```json
{
  "models": {
    "gradient_boosting": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "tfidf",
          "class": "sklearn.feature_extraction.text.TfidfVectorizer",
          "params": {}
        },
        {
          "name": "clf",
          "class": "sklearn.ensemble.GradientBoostingClassifier",
          "params": {
            "n_estimators": 100,
            "learning_rate": 0.1,
            "max_depth": 3
          }
        }
      ]
    }
  },
  "experiments": [
    {
      "model": "gradient_boosting",
      "param_grid": {
        "clf__n_estimators": [50, 100, 200],
        "clf__learning_rate": [0.01, 0.1, 0.5]
      }
    }
  ]
}
```

### Caso 3: Testar diferentes vetorizadores

```json
{
  "models": {
    "countvec_lr": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "vec",
          "class": "sklearn.feature_extraction.text.CountVectorizer",
          "params": {}
        },
        {
          "name": "clf",
          "class": "sklearn.linear_model.LogisticRegression",
          "params": {"max_iter": 2000}
        }
      ]
    },
    "hashvec_lr": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "vec",
          "class": "sklearn.feature_extraction.text.HashingVectorizer",
          "params": {}
        },
        {
          "name": "clf",
          "class": "sklearn.linear_model.LogisticRegression",
          "params": {"max_iter": 2000}
        }
      ]
    }
  }
}
```

---

## üé® Diagrama Visual

```
config/pipelines.json
‚îÇ
‚îú‚îÄ datasets          ‚îÄ‚îÄ‚Üí  Quais arquivos CSV usar
‚îÇ  ‚îî‚îÄ "arcaico_moderno": "train_arcaico_moderno.csv"
‚îÇ
‚îú‚îÄ cv_config         ‚îÄ‚îÄ‚Üí  Configura√ß√£o de valida√ß√£o cruzada
‚îÇ  ‚îú‚îÄ n_folds: 5
‚îÇ  ‚îî‚îÄ random_state: 42
‚îÇ
‚îú‚îÄ models            ‚îÄ‚îÄ‚Üí  COMO criar cada modelo
‚îÇ  ‚îú‚îÄ "tfidf_lr"
‚îÇ  ‚îÇ  ‚îî‚îÄ steps:
‚îÇ  ‚îÇ     ‚îú‚îÄ TfidfVectorizer
‚îÇ  ‚îÇ     ‚îî‚îÄ LogisticRegression
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ "sbert_lr"
‚îÇ     ‚îî‚îÄ factory: create_sbert_lr()
‚îÇ
‚îî‚îÄ experiments       ‚îÄ‚îÄ‚Üí  QUAIS modelos testar e COM QUAIS par√¢metros
   ‚îî‚îÄ model: "tfidf_lr"
      ‚îî‚îÄ param_grid:
         ‚îú‚îÄ max_features: [3000, 5000]
         ‚îî‚îÄ ngram_range: [[1,1], [1,3]]
```

---

## üß™ Testar Sua Configura√ß√£o

```python
# Criar arquivo: test_config.py
from src.ep1.config import get_default_config

config = get_default_config()

# 1. Ver datasets
print("üìÅ Datasets:", config.datasets)

# 2. Ver modelos
print("\nü§ñ Modelos:", list(config.models.keys()))

# 3. Testar cria√ß√£o de modelo
try:
    model = config.get_model("tfidf_lr")
    print("\n‚úÖ Modelo criado com sucesso!")
    print(model)
except Exception as e:
    print(f"\n‚ùå Erro: {e}")

# 4. Ver experimentos
experiments = config.get_experiments()
print(f"\nüß™ Total de experimentos: {len(experiments)}")
for name, factory, params in experiments[:3]:  # Primeiros 3
    print(f"  - {name}: {list(params.keys())}")
```

```bash
# Executar teste
uv run python test_config.py
```

---

## ‚ùì Perguntas Frequentes

### 1. O que significa `tfidf__max_features`?

- `tfidf`: Nome do step no pipeline
- `__`: Separador
- `max_features`: Par√¢metro da classe

```json
{
  "steps": [
    {"name": "tfidf", ...},  // ‚Üê Este nome
    {"name": "clf", ...}
  ]
}

// Para acessar par√¢metros:
// "tfidf__parametro" ‚Üí par√¢metros do vectorizer
// "clf__parametro" ‚Üí par√¢metros do classificador
```

### 2. Como sei quais par√¢metros posso usar?

Veja a documenta√ß√£o do sklearn:
- [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
- etc.

### 3. Posso usar qualquer classe do sklearn?

Sim! Basta colocar o caminho completo:
```json
{
  "class": "sklearn.ensemble.RandomForestClassifier"
}
```

### 4. E se eu quiser usar bibliotecas externas?

Use o tipo `"custom"` e crie uma fun√ß√£o Python que retorna o modelo.

---

## üéì Exerc√≠cio Pr√°tico

Tente criar este modelo no JSON:

**Objetivo:** Pipeline com HashingVectorizer + SVM

**Solu√ß√£o:**
```json
{
  "models": {
    "hash_svm": {
      "type": "sklearn_pipeline",
      "steps": [
        {
          "name": "hasher",
          "class": "sklearn.feature_extraction.text.HashingVectorizer",
          "params": {
            "n_features": 2048,
            "ngram_range": [1, 2]
          }
        },
        {
          "name": "clf",
          "class": "sklearn.svm.LinearSVC",
          "params": {
            "C": 1.0,
            "max_iter": 1000
          }
        }
      ]
    }
  },
  "experiments": [
    {
      "model": "hash_svm",
      "param_grid": {
        "hasher__n_features": [1024, 2048, 4096],
        "clf__C": [0.1, 1.0, 10.0]
      }
    }
  ]
}
```

---

## üìö Pr√≥ximos Passos

1. ‚úÖ Abra `config/pipelines.json`
2. ‚úÖ Veja os modelos existentes
3. ‚úÖ Tente modificar um par√¢metro
4. ‚úÖ Execute: `uv run examples_config.py`
5. ‚úÖ Crie seu pr√≥prio modelo!

---

**Ainda com d√∫vidas?** Execute:
```bash
uv run examples_config.py
```

Isso mostra exemplos pr√°ticos de como usar o sistema!
