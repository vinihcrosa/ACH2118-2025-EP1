ACH2118-2025-EP1
=================

Este projeto re√∫ne experimentos de classifica√ß√£o de estilo de texto usados na disciplina ACH2118. Os scripts trabalham com tr√™s conjuntos de dados (`train_arcaico_moderno.csv`, `train_complexo_simples.csv`, `train_literal_dinamico.csv`) e avaliam diversos classificadores tradicionais e neurais baseados em TF-IDF, SBERT e MLP.

## üöÄ In√≠cio R√°pido

### Instala√ß√£o
```bash
# Instalar depend√™ncias
uv sync

# Listar modelos dispon√≠veis
uv run predict_cli.py --list-models

# Classificar um texto
uv run predict_cli.py --model arcaico_moderno__tfidf_lr --text "Seu texto aqui" --proba
```

## üìö Documenta√ß√£o

- **[HOW_TO_PREDICT.md](HOW_TO_PREDICT.md)** - üéØ **COMECE AQUI!** Guia completo de como usar modelos treinados
- **[QUICKSTART.md](QUICKSTART.md)** - Guia r√°pido do sistema de configura√ß√£o JSON
- **[config/README.md](config/README.md)** - Documenta√ß√£o detalhada das configura√ß√µes
- **[MIGRATION.md](MIGRATION.md)** - Detalhes da migra√ß√£o para JSON
- **[PREDICT_GUIDE.md](PREDICT_GUIDE.md)** - Guia detalhado de predi√ß√£o

## üíª Principais Funcionalidades

### 1. Usar Modelos Treinados (Predi√ß√£o)

**CLI Simples:**
```bash
# Classificar texto
uv run predict_cli.py --model arcaico_moderno__tfidf_lr --text "Seu texto"

# Processar CSV
uv run predict_cli.py --model complexo_simples__tfidf_lr --csv dados.csv

# Comparar todos os modelos
uv run predict_cli.py --compare "Texto para comparar"
```

**Python:**
```python
from src.ep1.inference import ModelPredictor

predictor = ModelPredictor("models/arcaico_moderno__tfidf_lr.joblib")
predicao = predictor.predict("Seu texto aqui")
```

Ver exemplos completos: `uv run examples_inference.py`

### 2. Treinar Novos Modelos

```bash
uv run src/ep1/train.py \
  --dataset arcaico_moderno \
  --model tfidf_lr \
  --cv 10 \
  --save
```

### 3. Executar Experimentos

```bash
# Roda todos os experimentos configurados em config/pipelines.json
uv run python -m src.ep1.experiments
```

### 4. Gerar Relat√≥rios

```bash
uv run python -m src.ep1.report \
  --input experiments.csv \
  --output reports/experiments_report.md
```

Requisitos
----------
- Python 3.11+
- [uv](https://docs.astral.sh/uv/) para gerenciar depend√™ncias
- GPU opcional (apenas acelera os experimentos com MLP em PyTorch)

Configura√ß√£o
------------
1. Instale o `uv` seguindo a documenta√ß√£o oficial.
2. Dentro do diret√≥rio do projeto, resolva as depend√™ncias:
   ```bash
   uv sync
   ```

## ‚öôÔ∏è Configura√ß√£o via JSON

Todos os modelos e experimentos agora s√£o configurados atrav√©s de `config/pipelines.json`. Isso permite:

- ‚úÖ Adicionar novos modelos sem editar c√≥digo Python
- ‚úÖ Modificar par√¢metros facilmente
- ‚úÖ Configura√ß√µes versionadas e reproduz√≠veis
- ‚úÖ Suporte para modelos sklearn e customizados

**Exemplo de configura√ß√£o:**
```json
{
  "models": {
    "tfidf_lr": {
      "type": "sklearn_pipeline",
      "steps": [
        {"name": "tfidf", "class": "sklearn.feature_extraction.text.TfidfVectorizer", "params": {}},
        {"name": "clf", "class": "sklearn.linear_model.LogisticRegression", "params": {"max_iter": 2000}}
      ]
    }
  }
}
```

Ver mais: `config/README.md` ou `uv run examples_config.py`

Como rodar os experimentos
--------------------------
Executa toda a grade de valida√ß√£o cruzada para os modelos definidos em `config/pipelines.json` e grava os resultados em `experiments.csv`.
```bash
uv run python -m src.ep1.experiments
```

O script faz valida√ß√£o estratificada com k-folds (configur√°vel em `config/pipelines.json`). Para alterar modelos ou hiperpar√¢metros, edite `config/pipelines.json`.

Relat√≥rio autom√°tico
--------------------
Para gerar um resumo em Markdown com os resultados atuais do CSV:
```bash
uv run python -m src.ep1.report --input experiments.csv --output reports/experiments_report.md
```
O par√¢metro `--top` (opcional) permite limitar quantas linhas aparecer√£o por conjunto (`--top 5`, por exemplo). O arquivo final fica por padr√£o em `reports/experiments_report.md`.

Modelos implementados
---------------------
- `tfidf_lr`: Regress√£o log√≠stica sobre vetores TF-IDF.
- `tfidf_sgd`: Classificador linear otimizado com SGD (`log_loss`).
- `tfidf_pa`: Passive-Aggressive.
- `tfidf_ridge`: RidgeClassifier.
- `tfidf_cnb`: Complement Naive Bayes.
- `tfidf_nb`: Multinomial Naive Bayes (baseline simples).
- `tfidf_svc`: LinearSVC.
- `sbert_lr`: SBERT com regress√£o log√≠stica.
- `sbert_svc`: SBERT com LinearSVC.
- `torch_mlp`: MLP em PyTorch (via skorch) sobre TF-IDF.

Sa√≠da dos experimentos
----------------------
- `experiments.csv`: hist√≥rico cumulativo com m√©dia, desvio padr√£o e scores individuais por fold.

Outros scripts √∫teis
--------------------
- `src/ep1/train.py`: fluxo de treino para um modelo espec√≠fico (verifique o c√≥digo para detalhes).
- `src/ep1/predict.py`: gera previs√µes a partir de um modelo previamente treinado/salvo.

Dicas
-----
- Os caches de embeddings SBERT ficam em `cache/embeddings`. Remova essa pasta para regenerar vetores se alterar os dados ou modelos.
- O n√∫mero de combina√ß√µes cresce rapidamente com `ngram_range` estendido at√© `(1, 10)`; ajuste `max_features` ou reduza a grade se notar uso excessivo de mem√≥ria/tempo.
